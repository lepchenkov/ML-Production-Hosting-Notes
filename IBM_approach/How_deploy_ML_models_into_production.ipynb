{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to deploy ML models into production\n",
    "\n",
    "https://www.youtube.com/watch?v=-UYyyeYJAoQ\n",
    "Talk by Sumit Goyal, Software Engineer at IBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real value in DS project comes when you deploy the model on the web service. And deployment is rarely covered. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning workflow starts with business understanding, then followed by data understanding and data preparation. Then comes modelling, evaluation and deployment. \n",
    "\n",
    "But the work does not end with deployment.\n",
    "\n",
    "The data for the demo comes from https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment\n",
    "\n",
    "The really bad way to deal with the deployment is to create and train the model in python, then re-implement it in Java or C++ and then deploy into the Rest API. It is bad from time to value standpoint. \n",
    "\n",
    "There is also a PMML (Predictive Model Markup Language) but it is not very stable.\n",
    "\n",
    "The third way is to serialize the model and deploy it into the python web application serving a REST API. Serialized Object (a blob) is saved into database, and on top of the blob the database stores the version of the model, the name, type, ML Frameworks, Eval. metrics of the model, etc. And we need some sort of web framework, we load the model, create a route (like predict route), prepare the data, and then run the predict step and serve the prediction. In the ecommerce application when the transaction is created in the service, there is a call that is created to the ML endpoint of the REST API which asks is it a fraud or not. \n",
    "\n",
    "When the model is served into production it is not a toy anymore. And there are service requirements: max response time, availability, quality/confidence of prediction, max re-train time, monitor. If the model is re-training, does it mean that we can't use the model anymore?\n",
    "\n",
    "### Deployment with Cloud Foundry\n",
    "Cloud Foundry automates the deployment. https://www.cloudfoundry.org/ Takes care of application lifecycle management. Cloud Foundry has a concept of build pack, which is like a docker container. In a buildback we will say: connect to the database, load the model, import sklearn, import flask, create a route, prepare score data, run prediction, post-processing, return results. With Cloud Foundry you can scale an application from 5 calls/second to 1000 calls/second.\n",
    "\n",
    "1. Develop cloud foundry app\n",
    "2. CLI: push\n",
    "3. Set configuration\n",
    "4. predictions are served using post.\n",
    "\n",
    "##### The app.py that is deployed looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Cloudant library so the model can be downloaded into the application\n",
    "from cloudant import Cloudant\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "import atexit\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "app = Flask(__name__, static_url_path='')\n",
    "\n",
    "db_name = None\n",
    "model_id = None\n",
    "client = None\n",
    "db = None\n",
    "\n",
    "\n",
    "# credential in CloudFoundry are called VCAP_SERVICES\n",
    "if 'VCAP_SERVICES' in os.environ:\n",
    "    vcap = json.loads(os.getenv('VCAP_SERVICES'))\n",
    "    print('Found VCAP_SERVICES')\n",
    "    if 'cloudantNoSQLDB' in vcap:\n",
    "        creds = vcap['cloudantNoSQLDB'][0]['credentials']\n",
    "        user = creds['username']\n",
    "        password = creds['password']\n",
    "        url = 'htttps://' + creds['host']\n",
    "        client = Cloudant(user, password, url=url, connect=True)\n",
    "        db_name = os.getenv('MODELS_DB_NAME')\n",
    "        db = client.create_database(db_name, throw_on_exists=False)\n",
    "        model_id = os.getenv('MODEL_ID')\n",
    "    elif os.path.isfile('vcap-local.json'):\n",
    "        with open('vcap-local.json') as f:\n",
    "            vcap = json.load(f)\n",
    "            print('Found local VCAP_SERVICES file')\n",
    "            creds = vcap['services']['cloudantNoSQLDB'][0]['credentials']\n",
    "            user = creds['username']\n",
    "            password = creds['password']\n",
    "            urls = 'https://' + creds['host']\n",
    "            client = Cloudant(user, password, url=url, connect=True)\n",
    "            db_name = os.getenv('MODELS_DB_NAME')\n",
    "            db = client.create_database(db_name, throw_on_exists=False)\n",
    "            model_id = os.getenv('MODEL_ID')\n",
    "\n",
    "            \n",
    "doc = db[model_id]\n",
    "model_binary = doc.get_attachment(attachment='model')\n",
    "model = pickle.loads(model_binary)\n",
    "print('Loaded the model')\n",
    "\n",
    "# When running this app on local machine, default the port to 8000\n",
    "port = int(ps.getenv('PORT', 8000))\n",
    "\n",
    "@app.route('/')\n",
    "def root():\n",
    "    return app.send_static_file('index.html')\n",
    "\n",
    "@app.route('/api/predict', methods=['POST'])\n",
    "def score():\n",
    "    features = json.dumps(request.json['data'])\n",
    "    print('Incoming request for scoring')\n",
    "    print(features)\n",
    "    # read the data from POST call\n",
    "    df = pd.read_json(features, orient='index')\n",
    "    predictions = model.predict(df)\n",
    "    print('Responding with prediction: {}'.format(predictions))\n",
    "    return jsonify(np.array2string(predictions))\n",
    "\n",
    "\n",
    "@atexit.register\n",
    "def shutdown():\n",
    "    if client:\n",
    "        client.disconnect()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starts a wev server locally when type in CLI:\n",
    "python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### manifest.yml contains necessary configuration details to deploy the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "applications:\n",
    "- name: FraudDectectionAPI\n",
    "  host: fraud-detection-api-v1\n",
    "  memory: 1024mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf push command in CLI actually deploys the model. \n",
    "cf push "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment with Docker\n",
    "\n",
    "To deploy an app with docker and kubernetes, the only difference is using a dockerfile:\n",
    "\n",
    "FROM: python:3.6.3\n",
    "\n",
    "WORKDIR /app/\n",
    "\n",
    "COPY app.py setup.py vcap-local.json requirments.txt /app/\n",
    "\n",
    "RUN pip install -r ./requirements.txt\n",
    "\n",
    "COPY static /app/static\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "ENTRYPOINT python ./hello.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment with managed services \n",
    "Managed services like Microsoft Azure ML Studio, Amazon SageMaker, IBM Watson Machine Learning have one click deployment by providing a special SDK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one more talk\n",
    "https://www.youtube.com/watch?v=BJ2QVzGmb2w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
